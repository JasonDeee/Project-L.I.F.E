# Debug Guide - Project L.I.F.E

## ğŸ› Debug Giao Diá»‡n Chat vá»›i LM Studio

### Váº¥n Ä‘á» phá»• biáº¿n vÃ  cÃ¡ch kháº¯c phá»¥c

#### 1. KhÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c vá»›i LM Studio API

**Triá»‡u chá»©ng:**

- Connection status hiá»ƒn thá»‹ "Máº¥t káº¿t ná»‘i"
- KhÃ´ng thá»ƒ gá»­i tin nháº¯n
- Console hiá»ƒn thá»‹ lá»—i káº¿t ná»‘i

**CÃ¡ch debug:**

1. **Má»Ÿ Developer Console** (F12) vÃ  xem logs:

   ```
   ğŸ”— Attempting to connect to: http://192.168.1.3:1234
   ğŸ¯ Testing LM Studio direct connection to: http://192.168.1.3:1234
   âŒ LM Studio connection failed: [Error message]
   ```

2. **Kiá»ƒm tra LM Studio:**

   - Äáº£m báº£o LM Studio Ä‘ang cháº¡y
   - Kiá»ƒm tra model Ä‘Ã£ Ä‘Æ°á»£c load
   - XÃ¡c nháº­n server Ä‘ang listen trÃªn port 1234

3. **Kiá»ƒm tra network:**

   ```bash
   # Test káº¿t ná»‘i báº±ng curl
   curl http://192.168.1.3:1234/v1/models
   ```

4. **Kiá»ƒm tra CORS:**
   - LM Studio cáº§n enable CORS cho requests tá»« browser
   - Kiá»ƒm tra settings trong LM Studio

#### 2. Lá»—i CORS (Cross-Origin Resource Sharing)

**Triá»‡u chá»©ng:**

```
Access to fetch at 'http://192.168.1.3:1234/v1/models' from origin 'http://localhost:3000' has been blocked by CORS policy
```

**CÃ¡ch kháº¯c phá»¥c:**

1. Trong LM Studio settings, enable CORS
2. Hoáº·c run React app vá»›i proxy:
   ```json
   // package.json
   "proxy": "http://192.168.1.3:1234"
   ```

#### 3. WebSocket Connection Failed

**Triá»‡u chá»©ng:**

```
ğŸ”´ Socket connection error: Error: xhr poll error
âš ï¸ Cannot test WebSocket: Socket not connected
```

**Giáº£i thÃ­ch:**

- ÄÃ¢y lÃ  behavior bÃ¬nh thÆ°á»ng
- App hiá»‡n Ä‘ang dÃ¹ng direct HTTP API vá»›i LM Studio
- WebSocket sáº½ hoáº¡t Ä‘á»™ng khi cÃ³ Node.js backend

#### 4. Streaming Response khÃ´ng hoáº¡t Ä‘á»™ng

**Debug logs cáº§n tÃ¬m:**

```
ğŸ“¤ Sending message to LM Studio: [message]
ğŸ“¡ WebSocket not connected, using direct LM Studio API
âœ… Message sent successfully via direct API
```

**Náº¿u tháº¥y lá»—i:**

```
âŒ Send message error: [error details]
```

**CÃ¡ch kháº¯c phá»¥c:**

1. Kiá»ƒm tra model trong LM Studio cÃ³ há»— trá»£ streaming
2. Verify API endpoint `/v1/chat/completions`
3. Check request format

### Console Logs Cáº§n Xem

#### Khi app khá»Ÿi Ä‘á»™ng:

```
ğŸš€ SocketProvider mounted, attempting auto-connect
ğŸ”— Attempting to connect to: http://localhost:8000
ğŸ“¡ Socket instance created with options: {...}
ğŸ¯ Testing LM Studio direct connection to: http://192.168.1.3:1234
âœ… LM Studio direct connection successful: {...}
```

#### Khi gá»­i tin nháº¯n:

```
ğŸ“¤ Sending message to LM Studio: Hello
ğŸ“¡ WebSocket not connected, using direct LM Studio API
ğŸ”„ Updated LM Studio API URL to: http://192.168.1.3:1234
âœ… Message sent successfully via direct API
```

#### Khi test connection:

```
ğŸ§ª Testing connection - Socket: false Connected: false
ğŸ¯ Testing LM Studio direct connection to: http://192.168.1.3:1234
âœ… LM Studio connection successful: {...}
```

### Kiá»ƒm tra Configuration

#### 1. API URL trong localStorage:

```javascript
// Má»Ÿ console vÃ  check
localStorage.getItem("life_api_url");
// Should return: "http://192.168.1.3:1234"
```

#### 2. LM Studio Models:

```bash
curl http://192.168.1.3:1234/v1/models
# Should return JSON with available models
```

#### 3. Test chat endpoint:

```bash
curl -X POST http://192.168.1.3:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "local-model",
    "messages": [{"role": "user", "content": "Hello"}],
    "stream": false
  }'
```

### Common Fixes

#### 1. Reset API URL:

```javascript
// Trong console
localStorage.setItem("life_api_url", "http://192.168.1.3:1234");
location.reload();
```

#### 2. Clear cache:

```javascript
// Clear all app data
localStorage.clear();
sessionStorage.clear();
location.reload();
```

#### 3. Check Network Tab:

- Má»Ÿ DevTools > Network
- Thá»±c hiá»‡n test connection
- Xem request/response details

### Troubleshooting Steps

1. **Verify LM Studio is running:**

   - Open LM Studio
   - Load a model
   - Check server is started

2. **Test direct connection:**

   - Go to http://192.168.1.3:1234/v1/models in browser
   - Should see JSON response

3. **Check console logs:**

   - F12 > Console
   - Look for error messages
   - Verify connection flow

4. **Test message sending:**
   - Type a message in chat
   - Watch console for logs
   - Check for streaming response

### Expected Behavior

âœ… **Normal flow:**

```
User types message
  â†“
App tries WebSocket (fails - no backend)
  â†“
App falls back to direct LM Studio API
  â†“
Streaming response appears in chat
  â†“
Message completed successfully
```

âŒ **Error flow:**

```
User types message
  â†“
Direct API call fails
  â†“
Error message appears in chat
  â†“
Check console for specific error
```

### Contact & Support

Náº¿u váº«n gáº·p lá»—i sau khi thá»­ cÃ¡c bÆ°á»›c trÃªn:

1. Copy console logs
2. Note LM Studio version
3. Describe steps to reproduce
4. Include error messages

### Development Notes

- App hiá»‡n dÃ¹ng **direct HTTP API** vá»›i LM Studio
- **WebSocket** sáº½ Ä‘Æ°á»£c implement trong Node.js backend
- **Dual assistant** (JASON) sáº½ hoáº¡t Ä‘á»™ng khi cÃ³ backend
- Current architecture: **React â†’ Direct API â†’ LM Studio**
